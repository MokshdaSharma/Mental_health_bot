{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7780f35-2e3e-46bc-a3d3-8cb69c3dbd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, StackingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"students_mental_health_survey (1).csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d343684b-2626-4b64-878c-05ca7bd4e94b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Missing Values  Percentage (%)\n",
      "CGPA                       12        0.170891\n",
      "Substance_Use              15        0.213614\n"
     ]
    }
   ],
   "source": [
    "missing_values = df.isnull().sum()\n",
    "missing_percentage = (missing_values / len(df)) * 100\n",
    "missing_data = pd.DataFrame({'Missing Values': missing_values, 'Percentage (%)': missing_percentage})\n",
    "print(missing_data[missing_data['Missing Values'] > 0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f2cb1dc-acb7-43ab-afac-561e9f26ce8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\AppData\\Local\\Temp\\ipykernel_15884\\2951578509.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['CGPA'].fillna(df['CGPA'].mean(), inplace=True)\n",
      "C:\\Users\\lenovo\\AppData\\Local\\Temp\\ipykernel_15884\\2951578509.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Substance_Use'].fillna(df['Substance_Use'].mode()[0], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Filling missing CGPA with mean\n",
    "df['CGPA'].fillna(df['CGPA'].mean(), inplace=True)\n",
    "\n",
    "# Filling missing Substance_Use with mode\n",
    "df['Substance_Use'].fillna(df['Substance_Use'].mode()[0], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "979a994d-e07e-42ed-ad3b-b0b4af501e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "categorical_cols = ['Course', 'Gender', 'Relationship_Status', 'Sleep_Quality', \n",
    "                    'Physical_Activity', 'Diet_Quality', 'Social_Support', \n",
    "                    'Counseling_Service_Use', 'Chronic_Illness', \n",
    "                    'Extracurricular_Involvement', 'Residence_Type', \n",
    "                    'Substance_Use', 'Family_History']\n",
    "\n",
    "label_encoders = {}\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Feature Engineering\n",
    "df['Mental_Health_Score'] = (df['Stress_Level'] + df['Depression_Score'] + df['Anxiety_Score']) / 3\n",
    "df['Lifestyle_Score'] = (df['Sleep_Quality'] + df['Physical_Activity'] + df['Diet_Quality'] + df['Social_Support']) / 4\n",
    "df['Academic_Stress'] = df['Semester_Credit_Load'] * df['Stress_Level']\n",
    "df['Financial_Impact'] = df['Financial_Stress'] * (df['Depression_Score'] + df['Anxiety_Score']) / 2\n",
    "\n",
    "# Target variable\n",
    "y = (df['Mental_Health_Score'] > 2).astype(int)\n",
    "\n",
    "# Features\n",
    "df.drop(columns=['Mental_Health_Score', 'Stress_Level', 'Depression_Score', 'Anxiety_Score'], inplace=True)\n",
    "X = df.copy()\n",
    "\n",
    "# Scaling numerical features\n",
    "scaler = StandardScaler()\n",
    "numerical_cols = ['Lifestyle_Score', 'Academic_Stress', 'Financial_Impact', 'CGPA',\n",
    "                  'Financial_Stress', 'Semester_Credit_Load', 'Age']\n",
    "X[numerical_cols] = scaler.fit_transform(X[numerical_cols])\n",
    "\n",
    "# Balancing the data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "# Splitting the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42, stratify=y_resampled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "064bfaee-48d9-46ed-bd3b-5131721529cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightgbm in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (4.6.0)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from lightgbm) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from lightgbm) (1.13.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "60b977fd-b37d-4f34-8400-87a49b28405f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [12:44:13] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 3150, number of negative: 3149\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000680 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1799\n",
      "[LightGBM] [Info] Number of data points in the train set: 6299, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500079 -> initscore=0.000318\n",
      "[LightGBM] [Info] Start training from score 0.000318\n",
      "Voting Classifier Accuracy: 0.9575\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import StackingClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "voting_model = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('xgb', XGBClassifier(n_estimators=100, use_label_encoder=False, eval_metric='logloss', random_state=42)),\n",
    "        ('lgbm', LGBMClassifier(n_estimators=100, random_state=42)),\n",
    "        ('gb', GradientBoostingClassifier(n_estimators=100, random_state=42))\n",
    "    ],\n",
    "    voting='soft'  # or 'hard'\n",
    ")\n",
    "\n",
    "voting_model.fit(X_train, y_train)\n",
    "voting_pred = voting_model.predict(X_test)\n",
    "voting_acc = accuracy_score(y_test, voting_pred)\n",
    "\n",
    "print(f\"Voting Classifier Accuracy: {voting_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd5cf04-aa7f-45bd-b2ca-6e23336d1b78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
